{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c529e49c-5051-4acc-a8fb-087a3f4986d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "from torch_geometric.data import DataLoader\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.nn import GCNConv, ChebConv  # noqa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2fecfd4-189c-479a-97bd-78739d46ec10",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./SySeVR_GraphDataset_e3.pkl\", \"rb\") as f:\n",
    "    dataset = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "49f87af9-b8e2-4d1f-8ca5-04c0f333be7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# quick fix\n",
    "for i in range(len(dataset)):\n",
    "    dataset[i].x = dataset[i].x.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c19b4e9-4739-4b04-a993-581350e572c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(dataset, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85ccc372-c80a-46b7-b6e2-71c5b9fb0246",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = GCNConv(dataset[0].num_features, 16, cached=True, normalize=False)\n",
    "        # self.conv2 = GCNConv(16, dataset[0].num_classes, cached=True, normalize=False)\n",
    "        self.conv2 = GCNConv(16, 2, cached=True, normalize=False)\n",
    "        # self.conv1 = ChebConv(data.num_features, 16, K=2)\n",
    "        # self.conv2 = ChebConv(16, data.num_features, K=2)\n",
    "\n",
    "    def forward(self, arg_data):\n",
    "        x, edge_index, edge_weight = arg_data.x, arg_data.edge_index, arg_data.edge_attr\n",
    "        x = F.relu(self.conv1(x, edge_index, edge_weight))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index, edge_weight)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "655a248c-52ca-4d56-b92e-f2a175a5b452",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = Net().to(device)\n",
    "optimizer = torch.optim.Adam([\n",
    "    dict(params=model.conv1.parameters(), weight_decay=5e-4),\n",
    "    dict(params=model.conv2.parameters(), weight_decay=0)\n",
    "], lr=0.01)  # Only perform weight-decay on first convolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "decb5ce2-caef-46a0-aa8c-980644836d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "    tmp_cnt = 0\n",
    "    for data in loader:\n",
    "        tmp_cnt += 1\n",
    "        print(\"\\r# train batch={}/{}\".format(tmp_cnt, len(loader)), end=\"\")\n",
    "        optimizer.zero_grad()\n",
    "        tdata = data.to(device)\n",
    "        F.nll_loss(model(tdata)[tdata.train_mask], tdata.y[tdata.train_mask]).backward()\n",
    "        optimizer.step()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60b2fd83-76e6-4ad2-8581-2615a0533ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @torch.no_grad()\n",
    "# def test():\n",
    "#     model.eval()\n",
    "#     # accs = {\"train_mask\":[], \"val_mask\":[], \"test_mask\":[]}\n",
    "#     rp = {\"train_mask\":[], \"val_mask\":[], \"test_mask\":[]}\n",
    "#     np = {\"train_mask\":[], \"val_mask\":[], \"test_mask\":[]}\n",
    "#     tmp_cnt = 0\n",
    "#     for data in loader:\n",
    "#         tmp_cnt += 1\n",
    "#         print(\"\\r# test batch={}/{}\".format(tmp_cnt, len(loader)), end=\"\")\n",
    "#         tdata = data.to(device)\n",
    "#         logits = model(tdata)\n",
    "#         for tag, mask in tdata('train_mask', 'val_mask', 'test_mask'):\n",
    "#             if not any(mask):\n",
    "#                 # skip all False mask\n",
    "#                 continue\n",
    "#             pred = logits[mask].max(1)[1]\n",
    "#             # acc = pred.eq(tdata.y[mask]).sum().item() / mask.sum().item()\n",
    "#             # accs[tag].append(acc)\n",
    "#             rp[tag].append(pred.eq(tdata.y[mask]).sum().item())\n",
    "#             np[tag].append(mask.sum().item())\n",
    "#     print()\n",
    "#     # return [accs[\"train_mask\"], accs[\"val_mask\"], accs[\"test_mask\"]]\n",
    "#     return [\n",
    "#         sum(rp[\"train_mask\"]) / sum(np[\"train_mask\"]),\n",
    "#         sum(rp[\"val_mask\"]) / sum(np[\"val_mask\"]),\n",
    "#         sum(rp[\"test_mask\"]) / sum(np[\"test_mask\"])\n",
    "#     ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9efd1ad-bd33-493a-b93a-c30b2777fff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def test():\n",
    "    model.eval()\n",
    "    pred_sts = {\"train_mask\":[], \"val_mask\":[], \"test_mask\":[]}\n",
    "    y_sts = {\"train_mask\":[], \"val_mask\":[], \"test_mask\":[]}\n",
    "    tmp_cnt = 0\n",
    "    for data in loader:\n",
    "        tmp_cnt += 1\n",
    "        print(\"\\r# test batch={}/{}\".format(tmp_cnt, len(loader)), end=\"\")\n",
    "        tdata = data.to(device)\n",
    "        logits = model(tdata)\n",
    "        for tag, mask in tdata('train_mask', 'val_mask', 'test_mask'):\n",
    "            if not any(mask):\n",
    "                # skip all False mask\n",
    "                continue\n",
    "            pred = logits[mask].max(1)[1]\n",
    "            pred_sts[tag] += pred.tolist()\n",
    "            y_sts[tag] += tdata.y[mask].tolist()\n",
    "    print()\n",
    "    return pred_sts, y_sts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63fe227-ebd1-4694-985f-37e3ff8e8a16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# train batch=25842/25842\n",
      "# test batch=25842/25842\n",
      "Epoch: 001, Train: 0.8836, Val: 0.8815, Test: 0.8797\n",
      "Confusion matrix for test set:\n",
      "Predicted      0     1\n",
      "Actual                \n",
      "0          69664   208\n",
      "1           9716  2904\n",
      "# train batch=25842/25842\n",
      "# test batch=25842/25842\n",
      "Epoch: 002, Train: 0.8837, Val: 0.8816, Test: 0.8799\n",
      "Confusion matrix for test set:\n",
      "Predicted      0     1\n",
      "Actual                \n",
      "0          69748   124\n",
      "1           9783  2837\n",
      "# train batch=25842/25842\n",
      "# test batch=25842/25842\n",
      "Epoch: 003, Train: 0.8836, Val: 0.8816, Test: 0.8799\n",
      "Confusion matrix for test set:\n",
      "Predicted      0     1\n",
      "Actual                \n",
      "0          69745   127\n",
      "1           9783  2837\n",
      "# train batch=25842/25842\n",
      "# test batch=25842/25842\n",
      "Epoch: 004, Train: 0.8835, Val: 0.8816, Test: 0.8797\n",
      "Confusion matrix for test set:\n",
      "Predicted      0     1\n",
      "Actual                \n",
      "0          69749   123\n",
      "1           9803  2817\n",
      "# train batch=25842/25842\n",
      "# test batch=25842/25842\n",
      "Epoch: 005, Train: 0.8509, Val: 0.8816, Test: 0.8478\n",
      "Confusion matrix for test set:\n",
      "Predicted      0   1\n",
      "Actual              \n",
      "0          69854  18\n",
      "1          12539  81\n",
      "# train batch=5757/25842"
     ]
    }
   ],
   "source": [
    "best_val_acc = test_acc = 0\n",
    "for epoch in range(1, 201):\n",
    "    train()\n",
    "    # train_acc, val_acc, tmp_test_acc = test()\n",
    "    tmp_pred, tmp_y = test()\n",
    "    \n",
    "    train_acc = sum([tmp_pred[\"train_mask\"][i]==tmp_y[\"train_mask\"][i] for i in range(len(tmp_pred[\"train_mask\"]))]) / len(tmp_pred[\"train_mask\"])\n",
    "    val_acc = sum([tmp_pred[\"val_mask\"][i]==tmp_y[\"val_mask\"][i] for i in range(len(tmp_pred[\"val_mask\"]))]) / len(tmp_pred[\"val_mask\"])\n",
    "    test_acc = sum([tmp_pred[\"test_mask\"][i]==tmp_y[\"test_mask\"][i] for i in range(len(tmp_pred[\"test_mask\"]))]) / len(tmp_pred[\"test_mask\"])\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        test_acc = test_acc\n",
    "    log = 'Epoch: {:03d}, Train: {:.4f}, Val: {:.4f}, Test: {:.4f}'\n",
    "    print(log.format(epoch, train_acc, best_val_acc, test_acc))\n",
    "    \n",
    "    y_actu = pd.Series(tmp_y[\"test_mask\"], name='Actual')\n",
    "    y_pred = pd.Series(tmp_pred[\"test_mask\"], name='Predicted')\n",
    "    df_confusion = pd.crosstab(y_actu, y_pred)\n",
    "    # print(df_confusion)\n",
    "    print(\"Confusion matrix for test set:\\n{}\".format(df_confusion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b04dc2-37f2-4593-b7bf-2208ed0ac4d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830bfeb3-0bb5-4cf7-b04d-13b91f0eb58f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b950827f-257c-4462-a13e-eb1392a210fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba54ef4f-a785-4548-863c-17a411ab25f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "4d5b9114-a3f7-467d-8311-38fd3f90d895",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# test batch=20235/20235\n"
     ]
    }
   ],
   "source": [
    "tmp_pred, tmp_y = test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "1cc3ba95-b0eb-4f1b-a6a8-a4c4f689afd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "621f1b88-ba17-4421-8279-bf2c780d144f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[55320,    25],\n",
       "       [ 9502,   236]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(tmp_y[\"test_mask\"], tmp_pred[\"test_mask\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "0ff31cb8-eda7-44eb-8af0-ef8f9d37fac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "y_actu = pd.Series(tmp_y[\"test_mask\"], name='Actual')\n",
    "y_pred = pd.Series(tmp_pred[\"test_mask\"], name='Predicted')\n",
    "df_confusion = pd.crosstab(y_actu, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "1b909e85-6b3a-460f-a0d6-bdaad62ae2cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted      0    1\n",
      "Actual               \n",
      "0          55320   25\n",
      "1           9502  236\n"
     ]
    }
   ],
   "source": [
    "print(df_confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b113bc-c70b-4f9e-bf52-a3aa2e8c18e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
