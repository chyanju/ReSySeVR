{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a13eb02f-1aec-4956-85bc-a464c0591ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from igraph import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "870d9464-c62b-40d8-9b2d-39e999e9c033",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_id = \"014\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc78efea-b0e9-459e-85d8-c6a2a70b5074",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../SARD_pkl/pdg_db_dir{}.pkl\".format(batch_id), \"rb\") as f:\n",
    "    dt0 = pickle.load(f)\n",
    "with open(\"../SARD_pkl/pdg_db_dir{}_1hop.pkl\".format(batch_id), \"rb\") as f:\n",
    "    dt = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9eb11edd-e1c5-4f94-8a81-a52113437cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../SARD_raw/points_dir{}/arrayuse_slice_points.pkl\".format(batch_id), \"rb\") as f:\n",
    "    dt_arrayuse = pickle.load(f)\n",
    "\n",
    "# data format: [\n",
    "#     ([<node_id>, ...], <root_node_id>, <api_name>),\n",
    "#     ...\n",
    "# ]\n",
    "# e.g., (['407684'], '407677', 'fclose')\n",
    "with open(\"../SARD_raw/points_dir{}/sensifunc_slice_points.pkl\".format(batch_id), \"rb\") as f:\n",
    "    dt_sensitive = pickle.load(f)\n",
    "    \n",
    "with open(\"../SARD_raw/points_dir{}/integeroverflow_slice_points_new.pkl\".format(batch_id), \"rb\") as f:\n",
    "    dt_integer = pickle.load(f)\n",
    "    \n",
    "with open(\"../SARD_raw/points_dir{}/pointuse_slice_points.pkl\".format(batch_id), \"rb\") as f:\n",
    "    dt_pointuse = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc59116-0cbe-4646-bb4f-f363d589475d",
   "metadata": {},
   "source": [
    "### first extract all interesting subgraph (subgraph slicing, intra procedural)\n",
    "- note that all projects will be flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69ba1f2f-7c77-4e4b-b1a7-54eae2baf6a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# processing 1000/1000"
     ]
    }
   ],
   "source": [
    "# first index the whole dataset\n",
    "# <node_id>: (first_key, second_key, index)\n",
    "\n",
    "# note-important: should still use dt0 (0-hop) data here\n",
    "#                 since this data structure is associating a node to its primary location\n",
    "tmp_cnt = 0\n",
    "dt_node2kk = {}\n",
    "for p in dt0.keys():\n",
    "    tmp_cnt += 1\n",
    "    print(\"\\r# processing {}/{}\".format(tmp_cnt, len(dt0)), end=\"\")\n",
    "    for q in dt0[p].keys():\n",
    "        for r in dt0[p][q].vs:\n",
    "            assert r[\"name\"] not in dt_node2kk.keys()\n",
    "            dt_node2kk[r[\"name\"]] = (p,q,r.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e7ce2a5-379f-4d61-bff3-5b2114f28e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def worklist_add_preds(g, me):\n",
    "    worklist = [me.index]\n",
    "    retlist = []\n",
    "    nth = 0\n",
    "    while nth < len(worklist):\n",
    "        curr = worklist[nth]\n",
    "        retlist.append(curr)\n",
    "        for p in g.vs[curr].predecessors():\n",
    "            if p.index not in worklist:\n",
    "                worklist.append(p.index)\n",
    "        nth += 1\n",
    "    return retlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "342f7772-03d4-47b4-92c6-d21b71af65bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# processing 993/993, valid: 5288"
     ]
    }
   ],
   "source": [
    "# then process different kinds of interesting nodes\n",
    "tmp_cnt = 0\n",
    "arrayuse_subgraphs = []\n",
    "for p in dt_arrayuse.keys():\n",
    "    tmp_cnt += 1\n",
    "    print(\"\\r# processing {}/{}, valid: {}\".format(tmp_cnt, len(dt_arrayuse), len(arrayuse_subgraphs)), end=\"\")\n",
    "    for s in dt_arrayuse[p]:\n",
    "        for q in s[0]:\n",
    "            if q in dt_node2kk.keys():\n",
    "                k0, k1, k2 = dt_node2kk[q]\n",
    "                tmp_inode = dt[k0][k1].vs[k2]\n",
    "                tmp_nodes = worklist_add_preds(dt[k0][k1], tmp_inode)\n",
    "                tmp_subgraph = dt[k0][k1].subgraph(tmp_nodes)\n",
    "                # (subgraph, name of interesting node)\n",
    "                # ideally you should use index, but since the index may change between graphs\n",
    "                # still here we use 'name' attribute which is globally unique\n",
    "                arrayuse_subgraphs.append((tmp_subgraph, tmp_inode['name']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba94a296-e692-4797-a986-c19d45c2a331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# processing 976/976, valid: 11918"
     ]
    }
   ],
   "source": [
    "# then process different kinds of interesting nodes\n",
    "tmp_cnt = 0\n",
    "sensitive_subgraphs = []\n",
    "for p in dt_sensitive.keys():\n",
    "    tmp_cnt += 1\n",
    "    print(\"\\r# processing {}/{}, valid: {}\".format(tmp_cnt, len(dt_sensitive), len(sensitive_subgraphs)), end=\"\")\n",
    "    for s in dt_sensitive[p]:\n",
    "        for q in s[0]:\n",
    "            if q in dt_node2kk.keys():\n",
    "                k0, k1, k2 = dt_node2kk[q]\n",
    "                tmp_inode = dt[k0][k1].vs[k2]\n",
    "                tmp_nodes = worklist_add_preds(dt[k0][k1], tmp_inode)\n",
    "                tmp_subgraph = dt[k0][k1].subgraph(tmp_nodes)\n",
    "                # (subgraph, name of interesting node)\n",
    "                # ideally you should use index, but since the index may change between graphs\n",
    "                # still here we use 'name' attribute which is globally unique\n",
    "                sensitive_subgraphs.append((tmp_subgraph, tmp_inode['name']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb9245a1-2a4e-4930-b23e-d98287269aa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# processing 153/153, valid: 363"
     ]
    }
   ],
   "source": [
    "# then process different kinds of interesting nodes\n",
    "tmp_cnt = 0\n",
    "integer_subgraphs = []\n",
    "for p in dt_integer.keys():\n",
    "    tmp_cnt += 1\n",
    "    print(\"\\r# processing {}/{}, valid: {}\".format(tmp_cnt, len(dt_integer), len(integer_subgraphs)), end=\"\")\n",
    "    for s in dt_integer[p]:\n",
    "        for q in s[0]:\n",
    "            if q in dt_node2kk.keys():\n",
    "                k0, k1, k2 = dt_node2kk[q]\n",
    "                tmp_inode = dt[k0][k1].vs[k2]\n",
    "                tmp_nodes = worklist_add_preds(dt[k0][k1], tmp_inode)\n",
    "                tmp_subgraph = dt[k0][k1].subgraph(tmp_nodes)\n",
    "                # (subgraph, name of interesting node)\n",
    "                # ideally you should use index, but since the index may change between graphs\n",
    "                # still here we use 'name' attribute which is globally unique\n",
    "                integer_subgraphs.append((tmp_subgraph, tmp_inode['name']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6fe7bd6e-505f-4437-98b1-3ca12033b56f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# processing 976/976, valid: 11717"
     ]
    }
   ],
   "source": [
    "# then process different kinds of interesting nodes\n",
    "tmp_cnt = 0\n",
    "pointuse_subgraphs = []\n",
    "for p in dt_pointuse.keys():\n",
    "    tmp_cnt += 1\n",
    "    print(\"\\r# processing {}/{}, valid: {}\".format(tmp_cnt, len(dt_pointuse), len(pointuse_subgraphs)), end=\"\")\n",
    "    for s in dt_pointuse[p]:\n",
    "        for q in s[0]:\n",
    "            if q in dt_node2kk.keys():\n",
    "                k0, k1, k2 = dt_node2kk[q]\n",
    "                tmp_inode = dt[k0][k1].vs[k2]\n",
    "                tmp_nodes = worklist_add_preds(dt[k0][k1], tmp_inode)\n",
    "                tmp_subgraph = dt[k0][k1].subgraph(tmp_nodes)\n",
    "                # (subgraph, name of interesting node)\n",
    "                # ideally you should use index, but since the index may change between graphs\n",
    "                # still here we use 'name' attribute which is globally unique\n",
    "                pointuse_subgraphs.append((tmp_subgraph, tmp_inode['name']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa937b3-b173-4366-b51f-e8a9fd2eae9e",
   "metadata": {},
   "source": [
    "### then infer labels for every subgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "434164a0-1cfd-4874-80e8-1c64ed762106",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_function_nodes(g):\n",
    "    return [p for p in g.vs if p[\"type\"]==\"Function\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d4703970-3d8a-48a0-a7a8-c623fadbf42f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# processing 5289/5290"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Counter({False: 4038, True: 1252})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# all_subgraphs = arrayuse_subgraphs + sensitive_subgraphs + integer_subgraphs + pointuse_subgraphs\n",
    "all_subgraphs = arrayuse_subgraphs\n",
    "# all_subgraphs = sensitive_subgraphs\n",
    "# all_subgraphs = integer_subgraphs\n",
    "# all_subgraphs = pointuse_subgraphs\n",
    "\n",
    "\n",
    "all_subgraphs_labeled = []\n",
    "for pp in all_subgraphs:\n",
    "    print(\"\\r# processing {}/{}\".format(len(all_subgraphs_labeled), len(all_subgraphs)), end=\"\")\n",
    "    sg, _ = pp\n",
    "    tmp_func_list = get_function_nodes(sg)\n",
    "    # assert len(tmp_func_list) >= 1\n",
    "    if len(tmp_func_list) == 0:\n",
    "        # skip this one\n",
    "        continue\n",
    "    tmp_label = any([True if \"cwe\" in p[\"code\"].lower() else False for p in tmp_func_list])\n",
    "    # this will be (label, (graph, name of interesting node))\n",
    "    all_subgraphs_labeled.append((tmp_label, pp))\n",
    "    \n",
    "# show some statistics\n",
    "tmp_labels = [p[0] for p in all_subgraphs_labeled]\n",
    "from collections import Counter\n",
    "display(Counter(tmp_labels))\n",
    "\n",
    "\n",
    "# with open(\"../SARD_ready/all_subgraphs_dir{}.pkl\".format(batch_id), \"wb\") as f:\n",
    "with open(\"../SARD_ready/arrayuse_subgraphs_dir{}.pkl\".format(batch_id), \"wb\") as f:\n",
    "# with open(\"../SARD_ready/sensitive_subgraphs_dir{}.pkl\".format(batch_id), \"wb\") as f:\n",
    "# with open(\"../SARD_ready/integer_subgraphs_dir{}.pkl\".format(batch_id), \"wb\") as f:\n",
    "# with open(\"../SARD_ready/pointuse_subgraphs_dir{}.pkl\".format(batch_id), \"wb\") as f:\n",
    "    pickle.dump(all_subgraphs_labeled, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "59e44bb7-27f4-4929-a984-257437d6ef6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# processing 11923/11924"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Counter({True: 3786, False: 8138})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# all_subgraphs = arrayuse_subgraphs + sensitive_subgraphs + integer_subgraphs + pointuse_subgraphs\n",
    "# all_subgraphs = arrayuse_subgraphs\n",
    "all_subgraphs = sensitive_subgraphs\n",
    "# all_subgraphs = integer_subgraphs\n",
    "# all_subgraphs = pointuse_subgraphs\n",
    "\n",
    "\n",
    "all_subgraphs_labeled = []\n",
    "for pp in all_subgraphs:\n",
    "    print(\"\\r# processing {}/{}\".format(len(all_subgraphs_labeled), len(all_subgraphs)), end=\"\")\n",
    "    sg, _ = pp\n",
    "    tmp_func_list = get_function_nodes(sg)\n",
    "    # assert len(tmp_func_list) >= 1\n",
    "    if len(tmp_func_list) == 0:\n",
    "        # skip this one\n",
    "        continue\n",
    "    tmp_label = any([True if \"cwe\" in p[\"code\"].lower() else False for p in tmp_func_list])\n",
    "    # this will be (label, (graph, name of interesting node))\n",
    "    all_subgraphs_labeled.append((tmp_label, pp))\n",
    "    \n",
    "# show some statistics\n",
    "tmp_labels = [p[0] for p in all_subgraphs_labeled]\n",
    "from collections import Counter\n",
    "display(Counter(tmp_labels))\n",
    "\n",
    "\n",
    "# with open(\"../SARD_ready/all_subgraphs_dir{}.pkl\".format(batch_id), \"wb\") as f:\n",
    "# with open(\"../SARD_ready/arrayuse_subgraphs_dir{}.pkl\".format(batch_id), \"wb\") as f:\n",
    "with open(\"../SARD_ready/sensitive_subgraphs_dir{}.pkl\".format(batch_id), \"wb\") as f:\n",
    "# with open(\"../SARD_ready/integer_subgraphs_dir{}.pkl\".format(batch_id), \"wb\") as f:\n",
    "# with open(\"../SARD_ready/pointuse_subgraphs_dir{}.pkl\".format(batch_id), \"wb\") as f:\n",
    "    pickle.dump(all_subgraphs_labeled, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "951c2729-2eb6-4a64-95ac-ce428017ec67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# processing 364/365"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Counter({True: 109, False: 256})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# all_subgraphs = arrayuse_subgraphs + sensitive_subgraphs + integer_subgraphs + pointuse_subgraphs\n",
    "# all_subgraphs = arrayuse_subgraphs\n",
    "# all_subgraphs = sensitive_subgraphs\n",
    "all_subgraphs = integer_subgraphs\n",
    "# all_subgraphs = pointuse_subgraphs\n",
    "\n",
    "\n",
    "all_subgraphs_labeled = []\n",
    "for pp in all_subgraphs:\n",
    "    print(\"\\r# processing {}/{}\".format(len(all_subgraphs_labeled), len(all_subgraphs)), end=\"\")\n",
    "    sg, _ = pp\n",
    "    tmp_func_list = get_function_nodes(sg)\n",
    "    # assert len(tmp_func_list) >= 1\n",
    "    if len(tmp_func_list) == 0:\n",
    "        # skip this one\n",
    "        continue\n",
    "    tmp_label = any([True if \"cwe\" in p[\"code\"].lower() else False for p in tmp_func_list])\n",
    "    # this will be (label, (graph, name of interesting node))\n",
    "    all_subgraphs_labeled.append((tmp_label, pp))\n",
    "    \n",
    "# show some statistics\n",
    "tmp_labels = [p[0] for p in all_subgraphs_labeled]\n",
    "from collections import Counter\n",
    "display(Counter(tmp_labels))\n",
    "\n",
    "\n",
    "# with open(\"../SARD_ready/all_subgraphs_dir{}.pkl\".format(batch_id), \"wb\") as f:\n",
    "# with open(\"../SARD_ready/arrayuse_subgraphs_dir{}.pkl\".format(batch_id), \"wb\") as f:\n",
    "# with open(\"../SARD_ready/sensitive_subgraphs_dir{}.pkl\".format(batch_id), \"wb\") as f:\n",
    "with open(\"../SARD_ready/integer_subgraphs_dir{}.pkl\".format(batch_id), \"wb\") as f:\n",
    "# with open(\"../SARD_ready/pointuse_subgraphs_dir{}.pkl\".format(batch_id), \"wb\") as f:\n",
    "    pickle.dump(all_subgraphs_labeled, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e595e600-c9e3-4714-9561-57a72e0ae8af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# processing 11722/11723"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Counter({False: 10207, True: 1516})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# all_subgraphs = arrayuse_subgraphs + sensitive_subgraphs + integer_subgraphs + pointuse_subgraphs\n",
    "# all_subgraphs = arrayuse_subgraphs\n",
    "# all_subgraphs = sensitive_subgraphs\n",
    "# all_subgraphs = integer_subgraphs\n",
    "all_subgraphs = pointuse_subgraphs\n",
    "\n",
    "\n",
    "all_subgraphs_labeled = []\n",
    "for pp in all_subgraphs:\n",
    "    print(\"\\r# processing {}/{}\".format(len(all_subgraphs_labeled), len(all_subgraphs)), end=\"\")\n",
    "    sg, _ = pp\n",
    "    tmp_func_list = get_function_nodes(sg)\n",
    "    # assert len(tmp_func_list) >= 1\n",
    "    if len(tmp_func_list) == 0:\n",
    "        # skip this one\n",
    "        continue\n",
    "    tmp_label = any([True if \"cwe\" in p[\"code\"].lower() else False for p in tmp_func_list])\n",
    "    # this will be (label, (graph, name of interesting node))\n",
    "    all_subgraphs_labeled.append((tmp_label, pp))\n",
    "    \n",
    "# show some statistics\n",
    "tmp_labels = [p[0] for p in all_subgraphs_labeled]\n",
    "from collections import Counter\n",
    "display(Counter(tmp_labels))\n",
    "\n",
    "\n",
    "# with open(\"../SARD_ready/all_subgraphs_dir{}.pkl\".format(batch_id), \"wb\") as f:\n",
    "# with open(\"../SARD_ready/arrayuse_subgraphs_dir{}.pkl\".format(batch_id), \"wb\") as f:\n",
    "# with open(\"../SARD_ready/sensitive_subgraphs_dir{}.pkl\".format(batch_id), \"wb\") as f:\n",
    "# with open(\"../SARD_ready/integer_subgraphs_dir{}.pkl\".format(batch_id), \"wb\") as f:\n",
    "with open(\"../SARD_ready/pointuse_subgraphs_dir{}.pkl\".format(batch_id), \"wb\") as f:\n",
    "    pickle.dump(all_subgraphs_labeled, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a4abd0d-f62e-4409-b38b-53a6e178c4b9",
   "metadata": {},
   "source": [
    "#### view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "567b5f19-d531-4c95-9949-253d132df033",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tmp_graph, tmp_n = arrayuse_subgraphs[3]\n",
    "# # tmp_graph = dt[k0][k1]\n",
    "# for p in tmp_graph.vs:\n",
    "#     p[\"label_size\"]=10\n",
    "# visual_style = {}\n",
    "# visual_style[\"margin\"]=40\n",
    "# visual_style[\"bbox\"]=(400,400)\n",
    "# visual_style[\"vertex_label\"] = [\n",
    "#     \"{} \\n {}\".format(tmp_graph.vs[\"name\"][i], tmp_graph.vs[\"code\"][i]) \n",
    "#     for i in range(len(tmp_graph.vs[\"code\"]))\n",
    "# ]\n",
    "# plot(tmp_graph, **visual_style)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ea1375b6-5207-4d38-bab9-c638dd4281f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tmp_graph.vs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c81f5cd-fea0-40f2-9e2a-d4c025fe8ceb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676e706f-3553-489f-8333-944a8cecb2a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
